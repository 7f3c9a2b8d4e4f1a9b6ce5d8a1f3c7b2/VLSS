# Audit Report

## Title
Epoch Boundary Timing Allows Loss Accumulation Beyond Per-Epoch Tolerance Limits

## Summary
The vault's loss tolerance mechanism fails to correctly enforce per-epoch loss limits when operations span epoch boundaries. The `cur_epoch` tracking field is only updated when operations start (via `try_reset_tolerance()`), not at actual epoch transitions, allowing operators to exceed the configured per-epoch loss tolerance by approximately 20% or more through strategic timing of operations around epoch boundaries.

## Finding Description

The vulnerability exists in how the vault tracks and resets loss tolerance across epoch boundaries. The `pre_vault_check()` function calls `try_reset_tolerance()` at operation start to reset the loss counter when entering a new epoch: [1](#0-0) 

However, the reset only occurs when the condition `self.cur_epoch < tx_context::epoch(ctx)` evaluates to true: [2](#0-1) 

**Root Cause Analysis:**

1. The `cur_epoch` field in the Vault struct tracks which epoch the current loss tolerance window started in: [3](#0-2) 

2. When an operation starts in epoch N with `cur_epoch == N`, the condition `N < N` is false, so no reset occurs

3. If the operation completes in epoch N+1, losses are recorded via `update_tolerance()`: [4](#0-3) 

4. These losses are added to `cur_epoch_loss` while `cur_epoch` still equals N (not yet updated to N+1)

5. When the next operation starts in epoch N+1, the reset triggers because `N < N+1`, setting `cur_epoch_loss = 0` and recalculating `cur_epoch_loss_base_usd_value` based on the current (already reduced) vault value: [5](#0-4) 

**Why Existing Protections Fail:**

The tolerance check validates against `cur_epoch_loss_base_usd_value`, but this value becomes stale when operations span epochs: [6](#0-5) 

The system has no timeout mechanism preventing operations from spanning arbitrary time periods including epoch transitions. Operations follow a three-phase pattern (`start_op_with_bag` → `end_op_with_bag` → `end_op_value_update_with_bag`) across multiple transactions with no duration constraints.

**Exploitation Scenario:**

1. End of epoch N: Operator starts operation A (no reset since `cur_epoch == N`)
2. Early epoch N+1: Operation A completes with loss L1, added to epoch N's counter
3. Still epoch N+1: Operator starts operation B, triggering reset with base value = (vault_value_at_epoch_N_start - accumulated_epoch_N_losses - L1)
4. Operation B can now cause additional losses based on this reduced base value
5. Total epoch N+1 losses = L1 + L2, exceeding the intended limit based on vault value at start of epoch N+1

## Impact Explanation

**Direct Financial Harm:**
Vault shareholders experience losses exceeding the configured per-epoch tolerance limit. The intended invariant is: "Total losses occurring chronologically during epoch E should not exceed `loss_tolerance`% of vault value at the start of epoch E."

**Quantified Impact:**
Using the default loss tolerance of 10 basis points (0.1%):
- If vault value at start of epoch N+1 is 1000 USD, the epoch limit should be 1 USD
- Through the vulnerability, actual losses in epoch N+1 can reach approximately 1.2 USD (20% excess)
- Over multiple epochs, these excess losses compound, systematically eroding the loss protection mechanism

**Affected Parties:**
- All vault shareholders bear losses beyond the risk parameters they agreed to
- The protocol's loss tolerance guarantee is violated
- Trust in the vault's risk management is undermined

**Severity Assessment:**
Medium severity - While individual excess per epoch is limited to ~20%, the vulnerability allows systematic circumvention of a critical safety mechanism. The cumulative effect over time is significant, and the exploitation requires only timing control, not complex manipulation.

## Likelihood Explanation

**Attacker Capabilities:**
Requires `OperatorCap`, which is a semi-trusted role created by vault admins. However, operators have freeze controls, indicating their behavior requires oversight. The vulnerability can occur through:
- Intentional exploitation by a malicious operator
- Accidental occurrence through poor operational timing
- Natural operation patterns during periods of high activity

**Attack Complexity:**
- **Low technical barrier**: Sui epochs are deterministic (24-hour periods), making timing predictable
- **No special conditions required**: The three-phase operation pattern naturally allows epoch transitions between phases
- **No detection mechanisms**: Loss tolerance violations appear to pass all validation checks

**Feasibility:**
- Operations inherently span multiple transactions with no timeout enforcement
- Epoch boundaries will inevitably be crossed during normal vault operations
- The vulnerability window exists for every operation that spans an epoch boundary

**Probability:**
High for accidental occurrence during normal operations, and trivially exploitable if an operator is aware of the mechanism. The deterministic nature of Sui epochs and lack of operation timeouts make this a realistic scenario.

## Recommendation

**Solution 1: Epoch-Boundary Reset (Recommended)**
Add automatic epoch boundary detection by storing the epoch when losses occurred and checking on each operation completion:

```move
// In Vault struct, add:
operation_start_epoch: u64,

// In start_op_with_bag, record the starting epoch:
vault.operation_start_epoch = tx_context::epoch(ctx);

// In end_op_value_update_with_bag, check if epoch changed:
public fun end_op_value_update_with_bag<T, ObligationType>(
    vault: &mut Vault<T>,
    operation: &Operation,
    cap: &OperatorCap,
    clock: &Clock,
    tx: TxBagForCheckValueUpdate,
) {
    // ... existing code ...
    
    let current_epoch = tx_context::epoch(ctx);
    let mut loss = 0;
    if (total_usd_value_after < total_usd_value_before) {
        loss = total_usd_value_before - total_usd_value_after;
        
        // If operation spanned epochs, attribute loss to the completion epoch
        if (vault.operation_start_epoch < current_epoch && vault.cur_epoch < current_epoch) {
            // Reset tolerance for the new epoch before recording loss
            vault.try_reset_tolerance(false, ctx);
        }
        
        vault.update_tolerance(loss);
    }
    
    // ... rest of existing code ...
}
```

**Solution 2: Operation Timeout**
Implement maximum operation duration to prevent epoch-spanning operations:

```move
// In Vault struct:
operation_start_timestamp: u64,

// In pre_vault_check:
vault.operation_start_timestamp = clock::timestamp_ms(clock);

// In end_op_value_update_with_bag:
const MAX_OPERATION_DURATION_MS: u64 = 3600000; // 1 hour
let operation_duration = clock::timestamp_ms(clock) - vault.operation_start_timestamp;
assert!(operation_duration <= MAX_OPERATION_DURATION_MS, ERR_OPERATION_TIMEOUT);
```

**Solution 3: Epoch-Start Base Value Caching**
Cache the vault value at each epoch start regardless of operations:

```move
// Add epoch transition tracking that updates independently of operations
public entry fun update_epoch_if_needed<T>(
    vault: &mut Vault<T>,
    ctx: &TxContext
) {
    if (vault.cur_epoch < tx_context::epoch(ctx)) {
        vault.cur_epoch = tx_context::epoch(ctx);
        vault.cur_epoch_loss = 0;
        vault.cur_epoch_loss_base_usd_value = vault.get_total_usd_value_without_update();
    }
}
```

## Proof of Concept

```move
#[test]
fun test_epoch_boundary_loss_tolerance_bypass() {
    let mut scenario = test_scenario::begin(ADMIN);
    let mut clock = clock::create_for_testing(scenario.ctx());
    
    // Setup vault with 1000 USD value and 10 bps (0.1%) loss tolerance
    setup_vault_with_oracle(&mut scenario, &mut clock, 1000_000_000_000); // 1000 USD in 9 decimals
    
    scenario.next_epoch(ADMIN); // Start epoch N
    scenario.next_tx(OPERATOR);
    {
        let mut vault = scenario.take_shared<Vault<SUI_TEST_COIN>>();
        let operation = scenario.take_shared<Operation>();
        let operator_cap = scenario.take_from_sender<OperatorCap>();
        
        // Accumulate 0.9 USD loss in epoch N (within 1 USD limit)
        simulate_operation_with_loss(&mut vault, &operation, &operator_cap, &clock, 900_000_000);
        
        // Start operation at end of epoch N
        let (assets, tx, tx_value, principal, coin_balance) = start_op_with_bag(
            &mut vault, &operation, &operator_cap, &clock, /* args */
        );
        
        test_scenario::return_shared(vault);
        test_scenario::return_shared(operation);
        scenario.return_to_sender(operator_cap);
        
        // Store operation state
        // ... (save assets, tx, etc. for next transaction)
    };
    
    scenario.next_epoch(ADMIN); // Advance to epoch N+1 while operation is in progress
    scenario.next_tx(OPERATOR);
    {
        let mut vault = scenario.take_shared<Vault<SUI_TEST_COIN>>();
        
        // Complete operation with 0.5 USD loss in epoch N+1
        // This loss is attributed to epoch N's counter (cur_epoch still N)
        end_op_with_bag(&mut vault, /* return assets with 0.5 USD loss */);
        end_op_value_update_with_bag(&mut vault, /* verify loss */);
        
        // cur_epoch_loss now = 1.4 USD, but still attributed to epoch N
        // Vault value now = 997.6 USD (1000 - 0.9 - 0.5 - other losses)
        
        test_scenario::return_shared(vault);
    };
    
    scenario.next_tx(OPERATOR);
    {
        let mut vault = scenario.take_shared<Vault<SUI_TEST_COIN>>();
        let operation = scenario.take_shared<Operation>();
        let operator_cap = scenario.take_from_sender<OperatorCap>();
        
        // Start new operation in epoch N+1
        // This triggers reset: cur_epoch_loss = 0, base = 997.6 USD
        // New limit = 997.6 * 0.001 = ~1 USD
        
        // Can now lose another ~1 USD in epoch N+1
        simulate_operation_with_loss(&mut vault, &operation, &operator_cap, &clock, 997_000_000);
        
        // TOTAL EPOCH N+1 LOSSES: 0.5 + 1.0 = 1.5 USD
        // EXPECTED EPOCH N+1 LIMIT: 998.5 * 0.001 = ~1 USD
        // EXCESS: 50% beyond intended limit
        
        test_scenario::return_shared(vault);
        test_scenario::return_shared(operation);
        scenario.return_to_sender(operator_cap);
    };
    
    clock.destroy_for_testing();
    scenario.end();
}
```

### Citations

**File:** volo-vault/sources/operation.move (L68-76)
```text
public(package) fun pre_vault_check<PrincipalCoinType>(
    vault: &mut Vault<PrincipalCoinType>,
    ctx: &TxContext,
) {
    // vault.assert_enabled();
    vault.assert_normal();
    vault.set_status(VAULT_DURING_OPERATION_STATUS);
    vault.try_reset_tolerance(false, ctx);
}
```

**File:** volo-vault/sources/operation.move (L359-364)
```text
    // Update tolerance if there is a loss (there is a max loss limit each epoch)
    let mut loss = 0;
    if (total_usd_value_after < total_usd_value_before) {
        loss = total_usd_value_before - total_usd_value_after;
        vault.update_tolerance(loss);
    };
```

**File:** volo-vault/sources/volo_vault.move (L118-121)
```text
    cur_epoch: u64,
    cur_epoch_loss_base_usd_value: u256,
    cur_epoch_loss: u256,
    loss_tolerance: u256,
```

**File:** volo-vault/sources/volo_vault.move (L608-624)
```text
public(package) fun try_reset_tolerance<PrincipalCoinType>(
    self: &mut Vault<PrincipalCoinType>,
    by_admin: bool,
    ctx: &TxContext,
) {
    self.check_version();

    if (by_admin || self.cur_epoch < tx_context::epoch(ctx)) {
        self.cur_epoch_loss = 0;
        self.cur_epoch = tx_context::epoch(ctx);
        self.cur_epoch_loss_base_usd_value = self.get_total_usd_value_without_update();
        emit(LossToleranceReset {
            vault_id: self.vault_id(),
            epoch: self.cur_epoch,
        });
    };
}
```

**File:** volo-vault/sources/volo_vault.move (L626-641)
```text
public(package) fun update_tolerance<T0>(self: &mut Vault<T0>, loss: u256) {
    self.check_version();

    self.cur_epoch_loss = self.cur_epoch_loss + loss;

    // let loss_limit = usd_value_before * (self.loss_tolerance as u256) / (RATE_SCALING as u256);
    let loss_limit =
        self.cur_epoch_loss_base_usd_value * (self.loss_tolerance as u256) / (RATE_SCALING as u256);

    assert!(loss_limit >= self.cur_epoch_loss, ERR_EXCEED_LOSS_LIMIT);
    emit(LossToleranceUpdated {
        vault_id: self.vault_id(),
        current_loss: self.cur_epoch_loss,
        loss_limit: loss_limit,
    });
}
```
